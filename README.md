# GPT2 Dataset - EDA

**EDAì— ì‚¬ìš©í•œ ë°ì´í„°**:
webtext.test.jsonl, gpt2_k40.test.jsonl

- GPT-2 ëª¨ë¸ ì „ì²´ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ,
- label = 1ë¡œ ì§€ì •í•˜ê³ ,
- EDAëŠ” ì „ì²´ GPT-2 ë¬¶ìŒ vs Humanë§Œ ìˆ˜í–‰.

### ë³‘í•© í”Œë¡œìš°

1. train, test, valid ì‹¹ ë‹¤ ë³‘í•©
2. í•˜ë‚˜ë¡œ ë³‘í•©ëœ GPT-2 ëª¨ë¸ì„ train, test, validë¡œ split
3. test ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì„œ Humanê³¼ ë¹„êµ EDA

### split ë¹„ìœ¨

- **Train**: 250,000ê°œ ìƒ˜í”Œ
- **Validation**: 5,000ê°œ ìƒ˜í”Œ
- **Test**: 5,000ê°œ ìƒ˜í”Œ

ì „ì²´ 260,000ê°œ ìƒ˜í”Œ ì¤‘ ì•½ 96%ê°€ í›ˆë ¨ìš© ë°ì´í„°ë¡œ, ë‚˜ë¨¸ì§€ 4%ê°€ ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œ í• ë‹¹

**ìµœì¢… ë””ë ‰í† ë¦¬ êµ¬ì¡°**
```
ğŸ“‚ gpt-2-output-dataset/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ webtext.train.jsonl             # Human í…ìŠ¤íŠ¸ (Train)
â”‚   â”œâ”€â”€ webtext.valid.jsonl             # Human í…ìŠ¤íŠ¸ (Validation)
â”‚   â”œâ”€â”€ webtext.test.jsonl              # Human í…ìŠ¤íŠ¸ (Test)
â”‚
â”œâ”€â”€ data/merged_gpt2_k40/               # GPT-2 (top-k=40) ë³‘í•©ë³¸
â”‚   â”œâ”€â”€ gpt2_k40.train.jsonl            # GPT-2 í…ìŠ¤íŠ¸ (Train)
â”‚   â”œâ”€â”€ gpt2_k40.valid.jsonl            # GPT-2 í…ìŠ¤íŠ¸ (Validation)
â”‚   â”œâ”€â”€ gpt2_k40.test.jsonl             # GPT-2 í…ìŠ¤íŠ¸ (Test)
```
---

## 1. ë¬¸ì¥ ê¸¸ì´ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨

- ëª©ì : ë‘ í´ë˜ìŠ¤ì˜ êµ¬ì¡°ì  ì°¨ì´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´, ê° ë¬¸ì¥ì˜ ë‹¨ì–´ ìˆ˜ ë¶„í¬ë¥¼ ì‹œê°í™”í•˜ì—¬ ë¹„êµ.
- **ê²°ê³¼ í•´ì„**

| êµ¬ê°„ | í•´ì„ |
| --- | --- |
| 0~100 | Human: ì§§ì€ ë¬¸ì¥ ë¹„ìœ¨ì´ ë” ë†’ìŒ â†’ ë‹¨ë¬¸ ì¤‘ì‹¬ êµ¬ì¡° ì¡´ì¬
| 800~900 | GPT2: ì •í˜•í™”ëœ ê¸¸ì´ë¡œ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ê²½í–¥ â†’ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° (`max_length`) ì˜í–¥ ê°€ëŠ¥ì„±
| ~1000 | GPT2: ê±°ì˜ 1000ë‹¨ì–´ì— ê·¼ì ‘í•œ ë¬¸ì¥ì„ ìì£¼ ìƒì„±â†’ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° (`max_length`) ì˜í–¥ ê°€ëŠ¥ì„± 

![Image](https://github.com/user-attachments/assets/5bca2e9e-abde-4e0e-b68f-75e2968af7c8)

---

## 2. ë“±ì¥ ë¹ˆë„ìˆ˜ ì •ë¦¬

- ëª©ì : ì´ì§„ ë¶„ë¥˜ì˜ ìœ íš¨ Feature íƒìƒ‰
- ê·¸ë˜í”„ ê¸°ë°˜ ìœ íš¨ Feature í›„ë³´ ì •ë¦¬

| Lexical Feature | ì´ìœ  |
| --- | --- |
| `also` | ë¶ˆí•„ìš”í•œ ì ‘ì†ë¶€ì‚¬ ë°˜ë³µ ê²½í–¥ |
| `would`, `could` | ì¡°ê±´/ê°€ì •ë¬¸ ê³¼ë‹¤ ì‚¬ìš© |
| `get`, `make`, `want`, `think`, `see` | ì„œìˆ /ì˜ì§€/í–‰ë™ ì¤‘ì‹¬ í‘œí˜„ ë°˜ë³µ |
| `new`, `one`, `people` | ëª¨í˜¸í•˜ê±°ë‚˜ ì¼ë°˜í™”ëœ ëª…ì‚¬ â†’ ì„œì‚¬ ë°˜ë³µ êµ¬ì¡° ê°€ëŠ¥ì„±

![Image](https://github.com/user-attachments/assets/b216bf3c-e781-4669-8749-616483119689)

### ë‹¨ì–´ ë¹ˆë„ ë¹„êµ (Top 20 Words)

<table>
<tr>
<td>

####  Human ìƒìœ„ 20ê°œ ë‹¨ì–´

| ë‹¨ì–´ | ë¹ˆë„ |
|------|------|
| one   | 4994 |
| new   | 4028 |
| said  | 4028 |
| would | 3985 |
| also  | 3766 |
| like  | 3364 |
| people| 2928 |
| first | 2701 |
| two   | 2604 |
| get   | 2579 |
| even  | 2332 |
| time  | 2315 |
| could | 2307 |
| may   | 2185 |
| many  | 2078 |
| last  | 2043 |
| make  | 1983 |
| use   | 1819 |
| see   | 1720 |
| us    | 1685 |

</td>
<td>

#### GPT-2 ìƒìœ„ 20ê°œ ë‹¨ì–´

| ë‹¨ì–´ | ë¹ˆë„ |
|------|------|
| new    | 7047 |
| would  | 6723 |
| one    | 6634 |
| also   | 6295 |
| said   | 6126 |
| people | 6114 |
| get    | 4731 |
| like   | 4422 |
| first  | 4368 |
| make   | 4209 |
| going  | 3682 |
| could  | 3551 |
| time   | 3409 |
| want   | 3174 |
| two    | 3144 |
| many   | 2982 |
| even   | 2845 |
| think  | 2820 |
| see    | 2818 |
| use    | 2733 |

</td>
</tr>
</table>

---

## 3. Word Cloud

- ìœ„ì˜ ë¹ˆë„ìˆ˜ë¥¼ Word Cloudë¡œ ì‹œê°í™”

### 1) Human Text Word Cloud

![Image](https://github.com/user-attachments/assets/eb7d659e-a54d-4e69-9e4a-8cbb6a61b143)

### 2) GPT-2 Text Word Cloud

![Image](https://github.com/user-attachments/assets/7cacbb75-d045-4180-a187-f27f254d7b16)

---

## 4. íŠ¹ìˆ˜ ë¬¸ì, ìˆ«ì, ëŒ€ë¬¸ì ë¹„ìœ¨ í™•ì¸ (í†µê³„ ìš”ì•½)

- ëª©ì : AIëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì˜ëª»ëœ ë¬¸ì¥ ë¶€í˜¸ë‚˜ ìˆ«ì ì¡°í•©ì„ ë‹¤ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ.
- **EDA ë¶„ì„**

| í•­ëª© | Human í‰ê·  | GPT2 í‰ê·  | ì°¨ì´ í•´ì„ |
| --- | --- | --- | --- |
| length (í…ìŠ¤íŠ¸ ê¸¸ì´) | 2593.76 | **2881.80** | GPT2 ë¬¸ì¥ì´ ì•½ **11%** ë” ê¸º |
| num_caps (ëŒ€ë¬¸ì ìˆ˜) | **93.30** | 82.77 | GPT2 ëª¨ë¸ì—ì„œ ë¬¸ì¥ ì‹œì‘/ê³ ìœ ëª…ì‚¬ ì‚¬ìš© ë¶€ì¡± ê°€ëŠ¥ì„± ì¡´ì¬ |
| num_digits (ìˆ«ì ìˆ˜) | **28.50** | 20.17 | Humanì´ ìˆ«ìê°€ í¬í•¨ëœ ë¬¸ì¥(ë‚ ì§œ, ìˆ˜ì¹˜)ì„ ë” ìì£¼ ë‹¤ë£¸ |
| num_punct (ë¬¸ì¥ë¶€í˜¸ ìˆ˜) | 47.88 | **50.83** | ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ íë¦„ ìœ ì§€ ì‹œë„ë¡œ í•´ì„ ê°€ëŠ¥ |

![Image](https://github.com/user-attachments/assets/26b79a60-7bb6-43ad-bccb-3891278af503)

**Human**

| í•­ëª© | length | num_caps | num_digits | num_punct |
| --- | --- | --- | --- | --- |
| count | 5000 | 5000 | 5000 | 5000 |
| mean | 2593.76 | 93.3 | 28.5 | 47.88 |
| std | 1619.72 | 80.37 | 55.65 | 34.4 |
| min | 201 | 0 | 0 | 0 |
| 25% | 1097.75 | 39 | 4 | 19 |
| 50% | 2426.5 | 79 | 14 | 42 |
| 75% | 4268.25 | 127.25 | 32 | 75 |
| max | 5764 | 2132 | 979 | 680 |

**GPT2_k40**

| í•­ëª© | length | num_caps | num_digits | num_punct |
| --- | --- | --- | --- | --- |
| count | 5000 | 5000 | 5000 | 5000 |
| mean | 2881.8 | 82.77 | 20.17 | 50.83 |
| std | 1575.97 | 61.01 | 39.84 | 31.5 |
| min | 1 | 0 | 0 | 0 |
| 25% | 1465.75 | 41 | 2 | 25 |
| 50% | 2913.5 | 72 | 10 | 49 |
| 75% | 4425.75 | 111 | 24 | 75 |
| max | 6137 | 1023 | 1229 | 410 |

---

## 5. ìì£¼ ì“°ëŠ” ë¬¸ì¥ íŒŒì•…

### **n-gram ë¶„ì„ (2-gram)**

- ëª©ì : ë‹¨ì–´ ì¡°í•© íŒ¨í„´ì„ í†µí•´ GPT-2ê°€ ìì£¼ ì“°ëŠ” ë¬¸ì¥ íë¦„ì„ ì°¾ìŒ.
- ex). â€˜it isâ€™, â€˜in theâ€™, â€˜this is notâ€™ ë“±
- **EDA ë¶„ì„**
1. Human, GPT2 ëª¨ë‘ `'of the'`, `'in the'`, `'to the'` ë“± ì „ì¹˜ì‚¬ + ê´€ì‚¬ ì¡°í•©ì„ ë§ì´ ì‚¬ìš©.
2. GPT-2ì—ì„œ `'going to'`, `'you can'`, `'this is'` ë“±ì´ ì¶”ê°€ë¡œ ìƒìœ„ê¶Œì— ìœ„ì¹˜.
    â†’ êµ¬ì–´ì²´ì  í‘œí˜„ì´ ë‘ë“œëŸ¬ì§
    
3. GPT-2ì˜ 2-gram ë¹ˆë„ìˆ˜ê°€ ì „ë°˜ì ìœ¼ë¡œ Humanë³´ë‹¤ ë†’ìŒ. 
    â†’ ë” ë°˜ë³µì ì´ê³  íŠ¹ì •í•œ ë¬¸ì¥ êµ¬ì¡°ì— í¸ì¤‘
    
- **ê²°ê³¼ í•´ì„**
    
    **: GPT-2**
    
1. ìƒëŒ€ì ìœ¼ë¡œ ê³ ì •ëœ íŒ¨í„´ì„ ìì£¼ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„±ì€ ìˆì§€ë§Œ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•¨. (íŒ¨í„´ ê¸°ë°˜ ìƒì„± íŠ¹ì„±)
2. ë¯¸ë˜ í‘œí˜„ì„ ë§ì´ ì‚¬ìš© ("will be", "you can", "going to")

![Image](https://github.com/user-attachments/assets/01c50a3d-0957-48a8-beab-9fb70a94898c)

### 2-gram ë¹ˆë„ ë¹„êµ (Top 20 Pairs)

<table>
<tr>
<td>

####  Human ìƒìœ„ 2-gram

| 2-gram | Human ë¹ˆë„ |
|--------|-------------|
| of the     | 12688 |
| in the     | 10088 |
| to the     | 5694  |
| on the     | 4729  |
| for the    | 3619  |
| and the    | 3231  |
| to be      | 3157  |
| at the     | 2950  |
| with the   | 2763  |
| from the   | 2410  |
| that the   | 2395  |
| by the     | 1881  |
| it is      | 1870  |
| if you     | 1586  |
| is the     | 1586  |
| one of     | 1577  |
| will be    | 1540  |
| this is    | 1512  |
| it was     | 1507  |
| the first  | 1369  |

</td>
<td>

####  GPT-2 ìƒìœ„ 2-gram

| 2-gram | GPT-2 ë¹ˆë„ |
|--------|-------------|
| of the     | 16388 |
| in the     | 14291 |
| to the     | 6927  |
| on the     | 5731  |
| to be      | 5453  |
| for the    | 4974  |
| and the    | 4762  |
| that the   | 4383  |
| with the   | 3891  |
| at the     | 3601  |
| if you     | 3123  |
| it is      | 3093  |
| from the   | 2968  |
| the first  | 2884  |
| going to   | 2871  |
| this is    | 2495  |
| you can    | 2457  |
| will be    | 2430  |
| by the     | 2419  |
| it was     | 2410  |

</td>
</tr>
</table>

---

## 6. TF-IDF ì‹œê°í™”

- ëª©ì : ë‘ í´ë˜ìŠ¤ì— ëŒ€í•´ ì¤‘ìš”í•œ ë‹¨ì–´ë¥¼ TF-IDFë¡œ ì¶”ì¶œí•´ë³´ê³ , í´ë˜ìŠ¤ë¥¼ êµ¬ë¶„í•˜ëŠ” ë‹¨ì–´ë“¤ì„ ì‹œê°í™”.
- TF-IDF ì ìˆ˜:  í•´ë‹¹ í´ë˜ìŠ¤ (ex. GPT-2 í…ìŠ¤íŠ¸)ì—ë§Œ ìƒëŒ€ì ìœ¼ë¡œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë¥¼ ì°¾ê¸° ìœ„í•œ ìˆ˜ë‹¨.
- top_k=15ë¡œ ì„¤ì •
- **EDA ë¶„ì„**

| ê³µí†µ ë‹¨ì–´ | the, to, of, and, in, that, it, is, for, on |
| --- | --- |
| ì°¨ì´ì  | GPT2: we, this / Human: he, as |
- **ê²°ê³¼ í•´ì„**
1. ê³µí†µ ë‹¨ì–´ ë‹¤ìˆ˜ â†’ ì£¼ì œ ìì²´ëŠ” ìœ ì‚¬í•  ìˆ˜ ìˆìŒ.
2. GPT2: `'we'`, `'this'` ê°™ì€ ì¼ë°˜ì  ì£¼ì–´ í‘œí˜„ì„ ê°•ì¡°.
    
    â†’ ì£¼ê´€ì  ë¬¸ì¥ ê²½í–¥
    
3. Human: `'with'`, `'as'` ë“±ì˜ ë‹¨ì–´ê°€ ë“±ì¥ (ì—°ê²°ì–´).
    
    â†’ ì •ë³´ ì „ë‹¬ ë° ì„¤ëª… ì¤‘ì‹¬ ê²½í–¥
    

![Image](https://github.com/user-attachments/assets/cd590346-beb9-476a-9cee-ea589bf44548)

### TF-IDF ìƒìœ„ ë‹¨ì–´ ë¹„êµ

<table>
<tr>
<td>

####  Human TF-IDF ìƒìœ„ ë‹¨ì–´

| ë‹¨ì–´ | Human TF-IDF |
|------|---------------|
| the   | 0.2243 |
| to    | 0.1125 |
| and   | 0.1025 |
| of    | 0.1017 |
| in    | 0.0780 |
| that  | 0.0508 |
| is    | 0.0486 |
| for   | 0.0451 |
| it    | 0.0414 |
| on    | 0.0388 |
| you   | 0.0380 |
| with  | 0.0349 |
| he    | 0.0330 |
| as    | 0.0307 |
| was   | 0.0307 |

</td>
<td>

####  GPT-2 TF-IDF ìƒìœ„ ë‹¨ì–´

| ë‹¨ì–´ | GPT-2 TF-IDF |
|------|----------------|
| the   | 0.2516 |
| to    | 0.1338 |
| of    | 0.1076 |
| and   | 0.0980 |
| in    | 0.0853 |
| that  | 0.0727 |
| it    | 0.0551 |
| is    | 0.0533 |
| you   | 0.0532 |
| for   | 0.0458 |
| was   | 0.0407 |
| we    | 0.0404 |
| on    | 0.0390 |
| he    | 0.0363 |
| this  | 0.0356 |

</td>
</tr>
</table>

---

## 7. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¶„ì„ (Cosine Similarity)

- ëª©ì : GPT í…ìŠ¤íŠ¸ë“¤ë¼ë¦¬ëŠ” ì„œë¡œ ìœ ì‚¬í•œ ê²½í–¥ì´ ê°•í•œì§€, Human í…ìŠ¤íŠ¸ëŠ” ë” ë‹¤ì–‘ì„±ì„ ë„ëŠ”ì§€ ë¶„ì„.
- **ê²°ê³¼ í•´ì„**
1. GPT2 ë¬¸ì¥ë“¤ë¼ë¦¬ëŠ” ë” ìœ ì‚¬í•œ ë‹¨ì–´ êµ¬ì¡°ë¥¼ ê³µìœ . 
    
    â†’ í‘œí˜„ ë‹¤ì–‘ì„±ì´ ë‚®ê³  ë°˜ë³µì 
    
2. Human ë¬¸ì¥ì€ ì„œë¡œ ë‹¤ì–‘í•œ ì£¼ì œì™€ í‘œí˜„ ë°©ì‹ì„ í¬í•¨.
    
    â†’ ìœ ì‚¬ë„ëŠ” ë‚®ê³  í‘œí˜„ë ¥ì´ í’ë¶€
    

![image.png](image%207.png)

| ì¸¡ì • í•­ëª© | **Human** | **GPT-2** |
| --- | --- | --- |
| í‰ê·  Cosine ìœ ì‚¬ë„ | 0.2662 | 0.2968 |
| í‘œì¤€í¸ì°¨ | 0.1292 | 0.1203 |

---

## 8. í•´ì„ ì¢…í•© ê²°ë¡ 

| í•­ëª© | GPT-2 íŠ¹ì„± | Human íŠ¹ì„± |
| --- | --- | --- |
| ë‹¨ì–´ ì¡°í•© (n-gram) | ë°˜ë³µì , ì¼ìƒ í‘œí˜„ ìœ„ì£¼ | ì •ë³´ ì „ë‹¬ ì¤‘ì‹¬ì˜ êµ¬ë¬¸ |
| ìˆ«ì/ëŒ€ë¬¸ì ì‚¬ìš© | ë¶€ì¡± | ë‹¤ì–‘í•¨ |
| TF-IDF | ê³ ë¹ˆë„ ì¼ë°˜ ë‹¨ì–´ ìœ„ì£¼ | ë§¥ë½ ì˜ë¯¸ ì¤‘ì‹¬ ë‹¨ì–´ í¬í•¨ |
| ë¬¸ì¥ ìœ ì‚¬ë„ | ë†’ì€ ìœ ì‚¬ë„ â†’ íŒ¨í„´í™” | ë‚®ì€ ìœ ì‚¬ë„ â†’ ë‹¤ì–‘ì„± |

### **ì´í‰!**

<aside>

 GPT2_k40 ëª¨ë¸ì€ ìœ ì°½ì„±ì€ ë†’ì§€ë§Œ, ì°½ì˜ì„±ê³¼ **ì •ë³´ì„±** ì¸¡ë©´ì—ì„œ Human í…ìŠ¤íŠ¸ë³´ë‹¤ ë¶€ì¡±í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚œë‹¤. 

ì´ëŠ” ëª¨ë¸ì˜ ì œí•œëœ ë¬¸ë§¥ ì´í•´ ë° íŒ¨í„´ í•™ìŠµ ë°©ì‹ì˜ í•œê³„ë¥¼ ë°˜ì˜í•˜ë©°, ë¶„ë¥˜ ëª¨ë¸ êµ¬ì¶• ì‹œ ì´ëŸ¬í•œ ë°˜ë³µì„±/ìœ ì‚¬ì„±ì´ ì£¼ìš” featureë¡œ í™œìš©ë  ìˆ˜ ìˆë‹¤.

</aside>

---
---
# original readme
# gpt-2-output-dataset

This dataset contains:
- 250K documents from the WebText test set
- For each GPT-2 model (trained on the WebText training set), 250K random samples (temperature 1, no truncation) and 250K samples generated with Top-K 40 truncation

We look forward to the research produced using this data!

### Download

For each model, we have a training split of 250K generated examples, as well as validation and test splits of 5K examples.

All data is located in Google Cloud Storage, under the directory `gs://gpt-2/output-dataset/v1`.  (NOTE: everything has been migrated to Azure `https://openaipublic.blob.core.windows.net/gpt-2/output-dataset/v1/`)

There, you will find files:

- `webtext.${split}.jsonl`
- `small-117M.${split}.jsonl`
- `small-117M-k40.${split}.jsonl`
- `medium-345M.${split}.jsonl`
- `medium-345M-k40.${split}.jsonl`
- `large-762M.${split}.jsonl`
- `large-762M-k40.${split}.jsonl`
- `xl-1542M.${split}.jsonl`
- `xl-1542M-k40.${split}.jsonl`

where split is one of `train`, `test`, and `valid`.

We've provided a script to download all of them, in `download_dataset.py`.

#### Finetuned model samples

Additionally, we encourage research on detection of finetuned models.  We have released data under `gs://gpt-2/output-dataset/v1-amazonfinetune/` with samples from a GPT-2 full model finetuned to output Amazon reviews.

### Detectability baselines

We're interested in seeing research in detectability of GPT-2 model family generations.

We provide some [initial analysis](detection.md) of two baselines, as well as [code](./baseline.py) for the better baseline.

Overall, we are able to achieve accuracies in the mid-90s for Top-K 40 generations, and mid-70s to high-80s (depending on model size) for random generations.  We also find some evidence that adversaries can evade detection via finetuning from released models.

### Data removal requests

If you believe your work is included in WebText and would like us to remove it, please let us know at webtextdata@openai.com.
