{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1750158308284,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "dRPTeqdsOLV8",
    "outputId": "e58a8e07-0d7b-4e60-a28d-c412c54e661f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 18903,
     "status": "ok",
     "timestamp": 1750072922444,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "0hVJmvFCd91s",
    "outputId": "7e66c351-f9d6-41c5-c8e3-f17dc3262cd0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/MyDrive/AI_Human.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27979,
     "status": "ok",
     "timestamp": 1750158353996,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "f5wGX7E-PkXA"
   },
   "outputs": [],
   "source": [
    "!cp '/content/drive/MyDrive/AI_Human.csv' \"/content/\" # ÌïôÏäµÏö© Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "!cp '/content/drive/MyDrive/daigt.csv' \"/content/\" # ÌÖåÏä§Ìä∏Ïö© Îç∞Ïù¥ÌÑ∞ÏÖã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUkD9p7VP2wP"
   },
   "source": [
    "### üì¶ Install / Imports & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3737,
     "status": "ok",
     "timestamp": 1750158368130,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "VOxf0Ug1P0p_",
    "outputId": "6666ff4b-845e-4c8c-dbf6-e726363e3a0a"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,4,5,6,7\"\n",
    "\n",
    "import torch\n",
    "\n",
    "# GPU ÏÇ¨Ïö© Í∞ÄÎä•ÌïúÏßÄ ÌôïÏù∏\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"ÏÇ¨Ïö© Ï§ëÏù∏ GPU Ïù¥Î¶Ñ:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPUÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13783,
     "status": "ok",
     "timestamp": 1750158386960,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "n2UyNLWdP5iH",
    "outputId": "1737e0b4-dcb3-4941-a4a6-2fdaa07c4b3c"
   },
   "outputs": [],
   "source": [
    "import os, datetime as dt, json, random, numpy as np, pandas as pd, torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast, RobertaForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback, TrainerCallback,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import disable_caching\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmID4ETIP8Pc"
   },
   "source": [
    "### ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãùÏùÑ ÏúÑÌïú Ï°∞Ìï© Ïã§Ìóò (1) Îç∞Ïù¥ÌÑ∞ Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21366,
     "status": "ok",
     "timestamp": 1750158418737,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "jWQz2kGBP67X",
    "outputId": "a274576d-2d6f-4b69-d36e-318f6f16e5b4"
   },
   "outputs": [],
   "source": [
    "RAW_PATH = \"/content/AI_Human.csv\"\n",
    "assert os.path.exists(RAW_PATH), f\"{RAW_PATH} not found!\"\n",
    "\n",
    "df_raw = (\n",
    "    pd.read_csv(RAW_PATH, usecols=[\"Generation\", \"label\"])\n",
    "      .dropna(subset=[\"Generation\"])\n",
    "      .rename(columns={\"Generation\": \"text\"})\n",
    ")\n",
    "\n",
    "df_raw[\"text_norm\"] = df_raw[\"text\"].str.lower().str.strip()\n",
    "df_raw[\"label\"] = df_raw[\"label\"].astype(int)\n",
    "\n",
    "before, after = len(df_raw), df_raw[\"text_norm\"].nunique()\n",
    "df_raw = df_raw.drop_duplicates(subset=\"text_norm\")\n",
    "print(f\"Removed {before - after:,} exact duplicate rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnNCAxAPW1up"
   },
   "source": [
    "### ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãùÏùÑ ÏúÑÌïú Ï°∞Ìï© Ïã§Ìóò (2) Ïã§Ìóò ÏãúÏûë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1750158422623,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "iAS95n0CW4pH"
   },
   "outputs": [],
   "source": [
    "# 1) ÏÉòÌîåÎßÅ (Ï†ÑÏ≤¥ 10%)\n",
    "SEED = 42\n",
    "df_small = df_raw.sample(frac=0.10, random_state=SEED)\n",
    "\n",
    "# 2) train/val Î∂ÑÌï† (8:2)\n",
    "train_df_small, val_df_small = train_test_split(\n",
    "    df_small,\n",
    "    test_size=0.2,\n",
    "    stratify=df_small[\"label\"],\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370,
     "referenced_widgets": [
      "46e7cbce401b490b8be8cbc2b6871b0d",
      "32d267d38272473da58219b2f5cf887a",
      "06c51ab06dac4ed691c3adf525efd2c2",
      "f9fa3db69dd749a6a62c756640675b00",
      "acf291d4ac9d4dcc9877dbe14d8538f4",
      "998fceb91e7b4b0985d4db93a159308e",
      "b19666cf47b24ea2a9b3409930356050",
      "4ad4cf37208e401a94c2341da2c1bd5b",
      "b30541fa044e4b96831a861bb4ff82fe",
      "961ffd47be8b4dfea9650887f0eb7c25",
      "8a30e28f59ca4055adaaf70759d72d42",
      "13e5b5b07431444b803e60364afb5f45",
      "afcc1974f3994b3ab3d5ca9669aff954",
      "c098d79921e04c96ab25febd5508fd21",
      "943cb16f2bef4ff0953df0cd513da4c8",
      "210e7268d2e9431dbfacc6b1b4015fd7",
      "65f86a9c35414ce8bf892899baccfe5e",
      "8a1bd88547b541379be686af571ebd47",
      "72445718b52245e5ae843dd766e2b5ff",
      "f5b4b96afc0c4dad9ef205764c437ea8",
      "cd9d0c39d213406c85fc7e0323b59af5",
      "ae2369794fb74a1db4ebbf978edc02b7",
      "2e430d3d0fbe47a991b5e9935473168d",
      "5f6cf94853824df2924abe7496a52e17",
      "5f8052ad09aa4b078d3f5b699c2a20bf",
      "73077ef9633444daaf8849fe94aa5c6d",
      "ef73d367a1ce47a5b905d45ea87334fe",
      "6d2f66171eca4ab1859359de67be5cde",
      "75586729ce514dadafc3bce4980e9f1b",
      "f1beea1d6e96406fbef8b1d2de913724",
      "eec41721894e4e06bbfcde1ef7e094e7",
      "450cbdceb6804818a1ba7a8c77042a2e",
      "93cb93e4a63a4804b11fe118327ceedb",
      "fd84c321fee8405abb7890b9c8411113",
      "0b13fe994e8d407fa9f96e9c0db2d2e1",
      "5350fcd1811f42b580edc7e6570f6bd5",
      "822e8c24a9e0424aba2b72c6d9308135",
      "7dc0378a97af4dffbaa42aa16d7990f2",
      "ca63a223273244b09ce0dfe634e540ad",
      "dbdeae4ef6cf4945a9e5f2679c023fbb",
      "4dec429e105448248c6936645a363334",
      "df6788bfb1fb4faa82a5956ec8a9c126",
      "ca3b7fe1c3b142d88d9f7780478f7940",
      "a610df50eaf640318b38d243fc8c18fe",
      "9c20765e64864ffca6fbf5a7cb007619",
      "4968ed30e89d4495ae64ba733adf9082",
      "74338999a21f4811a545d09e89a64800",
      "e874ae0f2a0e4b80a58e13533ba14c97",
      "3039de22a9e046289c32e7129e505112",
      "c48633de42cf4a7dac39885824d86483",
      "9b5a919e947b44528f2b4330029db88d",
      "5ead217da8384a4a97cdc4dcce72f077",
      "ae98f215fa184a6fae7d50d1a806dc08",
      "bb68f08df08c432286315c428bf8eceb",
      "d1614cbd171f4d3b9f3af289f5266943",
      "d8b488fab4644b90816edf19decd5c88",
      "a6b7ac00bf7c464f9fde9cb408d8916c",
      "358506d8e89340b19769a903fa1e790c",
      "8666b65a6ae34269be147c55827d79bc",
      "a203ffdc22904316a8a017a264f2d2ed",
      "9c5ad5e9ea494be3bb6b89ed4eebb0a5",
      "2a078c2eaa7341f78cc2b77e03892019",
      "0da698053a674922ad7aedd87a88f47d",
      "0940a0e5d4bb40feb0b1f8b2226d5831",
      "6a10c752c4a343b0893d01f770a0168a",
      "f8f86ae6c2d0498ba7fed5290db3021f",
      "2ba43ce4a3194bfd9768df17eec822e2",
      "522eebc498954d4e8803c39704a8812a",
      "8e20561eff354fd2ab2776504a4461a4",
      "71e8633262da4cc98ab7b1610a05f999",
      "e24fb13d93bf47d08364c4dcf2baa4cd",
      "73d59287805d4196a3c66c669542fcf7",
      "4bfae13f5a98496db31f8b11be1f1640",
      "62ac0b7f6ae54a75a2310a0ac2e5c414",
      "0c863a42d10f4d2c85e2c1c442dd13f4",
      "fb584256c1054cb8b27ef25d97306110",
      "7a919e1f38a941edb5b67124378f56c8"
     ]
    },
    "executionInfo": {
     "elapsed": 97709,
     "status": "ok",
     "timestamp": 1750158522563,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "aBG_Sp85XH4v",
    "outputId": "a5faf224-0d18-4589-f974-25c2730aa7d5"
   },
   "outputs": [],
   "source": [
    "# 3) Tokenizer ÏÑ§Ï†ï\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "MAX_LEN = 512\n",
    "HEAD    = 256\n",
    "TAIL    = 254\n",
    "\n",
    "def head_tail_tokenize(batch):\n",
    "    encodings = {\"input_ids\": [], \"attention_mask\": []}\n",
    "    for text in batch[\"text\"]:\n",
    "        ids = tokenizer.encode(text, add_special_tokens=True, truncation=False)\n",
    "        if len(ids) > MAX_LEN:\n",
    "            ids = ids[: HEAD + 1] + ids[-TAIL:]\n",
    "            ids = ids[:MAX_LEN]\n",
    "        attn = [1] * len(ids)\n",
    "        encodings[\"input_ids\"].append(ids)\n",
    "        encodings[\"attention_mask\"].append(attn)\n",
    "    return encodings\n",
    "\n",
    "# 4) Dataset Î≥ÄÌôò Î∞è ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï\n",
    "disable_caching()\n",
    "\n",
    "train_ds_small = Dataset.from_pandas(train_df_small[[\"text\", \"label\"]]).map(\n",
    "    head_tail_tokenize, batched=True, remove_columns=[\"text\"], num_proc=1\n",
    ")\n",
    "val_ds_small = Dataset.from_pandas(val_df_small[[\"text\", \"label\"]]).map(\n",
    "    head_tail_tokenize, batched=True, remove_columns=[\"text\"], num_proc=1\n",
    ")\n",
    "\n",
    "# 5) Collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1435299,
     "status": "ok",
     "timestamp": 1750161636768,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "0d6eXnmVpE6a",
    "outputId": "aea7f865-9fed-488e-e3a0-605c6107b5ab"
   },
   "outputs": [],
   "source": [
    "# ÌäúÎãù ÏûêÎèôÌôî\n",
    "# ÌäúÎãù ÎåÄÏÉÅ Ï°∞Ìï© Ï†ïÏùò\n",
    "configs = [\n",
    "    {\"name\": \"baseline\",       \"lr\": 2e-5, \"wd\": 0.01},\n",
    "    {\"name\": \"high_lr\",        \"lr\": 3e-5, \"wd\": 0.01},\n",
    "    {\"name\": \"strong_decay\",   \"lr\": 2e-5, \"wd\": 0.1},\n",
    "]\n",
    "\n",
    "# ÏÑ±Îä• ÏßÄÌëú\n",
    "def compute_metrics(pred):\n",
    "    y_true = pred.label_ids\n",
    "    y_pred = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\":    recall_score(y_true, y_pred),\n",
    "        \"f1\":        f1_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# Î°úÍ∑∏ ÏΩúÎ∞±\n",
    "class LogCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            now = dt.datetime.now().strftime(\"%H:%M:%S\")\n",
    "            # ÏïàÏ†ïÏ†ÅÏúºÎ°ú logsÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "            lr = logs.get(\"learning_rate\", 0.0)\n",
    "            watched = {\n",
    "                \"loss\": logs.get(\"loss\"),\n",
    "                \"eval_loss\": logs.get(\"eval_loss\"),\n",
    "                \"eval_accuracy\": logs.get(\"eval_accuracy\"),\n",
    "                \"eval_f1\": logs.get(\"eval_f1\"),\n",
    "                \"lr\": lr,\n",
    "            }\n",
    "            # msg = \" | \".join(f\"{k}: {v:.4f}\" for k,v in watched.items() if v is not None)\n",
    "            msg = \" | \".join(f\"{k}: {v:.6f}\" if k == \"lr\" else f\"{k}: {v:.4f}\" for k,v in watched.items() if v is not None)\n",
    "            print(f\"[{now}] step {state.global_step} | {msg}\")\n",
    "\n",
    "\n",
    "# Ïã§Ìóò Î∞òÎ≥µ\n",
    "for cfg in configs:\n",
    "    print(f\"\\nüöÄ Ïã§Ìóò ÏãúÏûë: {cfg['name']}\")\n",
    "\n",
    "    # Í≥†Ïú† Î°úÍ∑∏/Î™®Îç∏ Ï†ÄÏû• Í≤ΩÎ°ú\n",
    "    timestamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_id = f\"{cfg['name']}_lr{cfg['lr']}_wd{cfg['wd']}_{timestamp}\"\n",
    "\n",
    "    # Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        \"roberta-base\",\n",
    "        num_labels=2,\n",
    "        hidden_dropout_prob=0.2,\n",
    "        attention_probs_dropout_prob=0.2,\n",
    "    ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # ÌïôÏäµ ÏÑ§Ï†ï\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"/content/tune_outputs/{run_id}\",\n",
    "        per_device_train_batch_size=56,\n",
    "        per_device_eval_batch_size=16,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=cfg['lr'],\n",
    "        warmup_ratio=0.1,           # Ï†ÑÏ≤¥ ÌïôÏäµ Ïä§ÌÖù Ï§ë 10%Î•º warmup\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        weight_decay=cfg['wd'],\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        label_smoothing_factor=0.1,\n",
    "        eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_dir=f\"/content/logs/{run_id}\",\n",
    "        logging_steps=10, logging_first_step=True,\n",
    "        save_total_limit=1,\n",
    "        run_name=run_id,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        ddp_find_unused_parameters=False,\n",
    "    )\n",
    "\n",
    "    # Trainer Íµ¨ÏÑ±\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds_small,\n",
    "        eval_dataset=val_ds_small,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2), LogCallback()],\n",
    "    )\n",
    "\n",
    "    # ÌïôÏäµ Ïã§Ìñâ\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnv3Ir6Yypvv"
   },
   "source": [
    "### üßπ Load & clean raw data (dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21072,
     "status": "ok",
     "timestamp": 1750162366673,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "WbckqyrQynlK",
    "outputId": "42f957d1-ee2d-4781-8fc6-1e0e76cdb7e4"
   },
   "outputs": [],
   "source": [
    "RAW_PATH1 = \"/content/AI_Human.csv\"\n",
    "assert os.path.exists(RAW_PATH1), f\"{RAW_PATH1} not found!\"\n",
    "\n",
    "df_raw1 = (\n",
    "    pd.read_csv(RAW_PATH1, usecols=[\"Generation\", \"label\"])\n",
    "      .dropna(subset=[\"Generation\"])\n",
    "      .rename(columns={\"Generation\": \"text\"})\n",
    ")\n",
    "\n",
    "df_raw1[\"text_norm\"] = df_raw1[\"text\"].str.lower().str.strip()\n",
    "df_raw1[\"label\"] = df_raw1[\"label\"].astype(int)\n",
    "\n",
    "before, after = len(df_raw1), df_raw1[\"text_norm\"].nunique()\n",
    "df_raw1 = df_raw1.drop_duplicates(subset=\"text_norm\")\n",
    "print(f\"Removed {before - after:,} exact duplicate rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSM-ZIj3P-0l"
   },
   "source": [
    "### ‚úÇÔ∏è Split or load cached splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13855,
     "status": "ok",
     "timestamp": 1750162449666,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "nzb6KizRP_u0",
    "outputId": "3bc59807-b8e0-474a-98b0-92243b55769e"
   },
   "outputs": [],
   "source": [
    "CACHE_DIR = \"splits_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "paths = {name: f\"{CACHE_DIR}/{name}.parquet\" for name in [\"train\", \"val\", \"test\"]}\n",
    "\n",
    "if all(os.path.exists(p) for p in paths.values()):\n",
    "    print(\"üìÇ Cached splits found ‚Äì loading.\")\n",
    "    train_df = pd.read_parquet(paths[\"train\"])\n",
    "    val_df   = pd.read_parquet(paths[\"val\"])\n",
    "    test_df  = pd.read_parquet(paths[\"test\"])\n",
    "else:\n",
    "    print(\"‚öôÔ∏è  Creating new splits.\")\n",
    "    gss1 = GroupShuffleSplit(train_size=0.8, random_state=SEED, n_splits=1)\n",
    "    train_idx, temp_idx = next(gss1.split(df_raw1, groups=df_raw1[\"text_norm\"]))\n",
    "    train_df = df_raw1.iloc[train_idx]\n",
    "    temp_df  = df_raw1.iloc[temp_idx]\n",
    "\n",
    "    gss2 = GroupShuffleSplit(train_size=0.5, random_state=SEED, n_splits=1)\n",
    "    val_idx, test_idx = next(gss2.split(temp_df, groups=temp_df[\"text_norm\"]))\n",
    "    val_df  = temp_df.iloc[val_idx]\n",
    "    test_df = temp_df.iloc[test_idx]\n",
    "\n",
    "    train_df.to_parquet(paths[\"train\"])\n",
    "    val_df.to_parquet(paths[\"val\"])\n",
    "    test_df.to_parquet(paths[\"test\"])\n",
    "    print(\"Splits saved to 'splits_cache/'.\")\n",
    "\n",
    "overlap = set(train_df[\"text_norm\"]) & set(val_df[\"text_norm\"])\n",
    "print(\"train ‚à© val duplicates:\", len(overlap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnCHyiMQQCQ2"
   },
   "source": [
    "### üî† Tokenize & build HF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "1dcf3b7e12f84d6383177255310953fb",
      "1fed68e88bdb4f42a5cf462687b12974",
      "8371abf5da7243008a7845508833a086",
      "432b591316d44606ad818bc677404975",
      "6b25fc48114e410aa31c7bed58149eda",
      "814c720289634651a1ad421620a821f7",
      "1ab420d9c82348939fe9eea27f3e22f5",
      "4c500a54f14d44ce99dc0b5a75fbfc5c",
      "087d4b27058f4e1f94cddffc3cfce1b8",
      "5cf668a5b8694d34a97041f8f9aca589",
      "4604b32030fd49c9a58111d45ef876f5"
     ]
    },
    "executionInfo": {
     "elapsed": 132807,
     "status": "ok",
     "timestamp": 1750162593633,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "_XjxzZGWQDIW",
    "outputId": "4b3b3014-ba14-4be0-a9c4-415f9ef22208"
   },
   "outputs": [],
   "source": [
    "tok = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "ds = Dataset.from_pandas(df_raw[[\"text\"]], preserve_index=False)\n",
    "\n",
    "def add_len(batch):\n",
    "    batch[\"tok_len\"] = [len(t) for t in tok(batch[\"text\"], add_special_tokens=True)[\"input_ids\"]]\n",
    "    return batch\n",
    "\n",
    "disable_caching()\n",
    "\n",
    "ds = ds.map(add_len, batched=True, batch_size=1024, num_proc=1, desc=\"Adding token lengths\")\n",
    "lengths = ds[\"tok_len\"]\n",
    "\n",
    "pct = np.percentile(lengths, [50, 90, 95, 99])\n",
    "print(\"median / p90 / p95 / p99 =\", pct)\n",
    "print(\"max =\", max(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "ef28d2a9bb0f4af3a4bead346fca8ee5",
      "f7886a71d9514a829db4d3df8df798c0",
      "85a9364a5a044e65bca41920a559164d",
      "ee97f602c4a24f41a44afd20040a167b",
      "5bd547d1205c467498dfb8205bf82e1c",
      "6d555909718846c48962bb01e09fa7db",
      "48f61803508640b0acfc3d9eb71e6027",
      "402d7022b5d140e7b169343918c0c143",
      "0f566419ef3f4351ac1f3259e4e19ec0",
      "91cbb040350f4273bf32f95fbf176651",
      "f00af3a1b78b4705b4afee426bb5cfc6",
      "0d9cd4d5929e4bd5aad0837715e53758",
      "5e279c9aacf140028a5ebd0edd451302",
      "6076f68127864053b5bbd4fac4cf8a15",
      "31ab18ed83ae4804bbe515bcfed1d766",
      "27e33b7bc0cf42d98c4efb53425df2a5",
      "77edd3e0ef874e20941d6a72ff757abe",
      "0247bb1fa95f47beb6b2b771fb73ca64",
      "0bf68cd56f114688b6da5662f1d2259c",
      "1ddabc8cd3824476961fc0550bbba0e8",
      "ea8fefd07fc94c35b2e6e8ceab9028c1",
      "d4727d8219dc4453a4c0edbb0f8967ad",
      "2b4e8ca9e8c64d9989cb0f976576714a",
      "457196f805c843298769f3bd7ef73faa",
      "502270ebfff54628900e55607369876f",
      "9d925b5624324d659c67c3f333a8a3ea",
      "68f7ec320de6403aa5b43ace467ad8ef",
      "6f1c0e9eec35460da3cb2af877328cfb",
      "9519cdb16af243be99d6f60df3ad5fbc",
      "72778fa2ef92450ab5d1a7118771219f",
      "c8a199816c0c4291928ccbc412931891",
      "f0caad429e6f4b1fb3ee82d5cccec100",
      "874aab83769e4e1a9f40395e2576ec4c"
     ]
    },
    "executionInfo": {
     "elapsed": 1011007,
     "status": "ok",
     "timestamp": 1750163649094,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "VawV3mj8QEzQ",
    "outputId": "626f8c33-fa02-42ac-a7e1-c44f88927936"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "MAX_LEN = 512\n",
    "HEAD    = 256\n",
    "TAIL    = 254\n",
    "\n",
    "def head_tail_tokenize(batch):\n",
    "    encodings = {\"input_ids\": [], \"attention_mask\": []}\n",
    "    for text in batch[\"text\"]:\n",
    "        ids = tokenizer.encode(text, add_special_tokens=True, truncation=False)\n",
    "        if len(ids) > MAX_LEN:\n",
    "            # ids[0] : <s>, ids[-1] : </s>\n",
    "            new_ids = ids[: HEAD + 1] + ids[-TAIL:]\n",
    "            ids = new_ids[:MAX_LEN]\n",
    "        attn = [1] * len(ids)\n",
    "        encodings[\"input_ids\"].append(ids)\n",
    "        encodings[\"attention_mask\"].append(attn)\n",
    "    return encodings\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[[\"text\", \"label\"]]).map(\n",
    "    head_tail_tokenize, batched=True, remove_columns=[\"text\"], num_proc = 1\n",
    ")\n",
    "val_ds = Dataset.from_pandas(val_df[[\"text\", \"label\"]]).map(\n",
    "    head_tail_tokenize, batched=True, remove_columns=[\"text\"], num_proc = 1\n",
    ")\n",
    "test_ds = Dataset.from_pandas(test_df[[\"text\", \"label\"]]).map(\n",
    "    head_tail_tokenize, batched=True, remove_columns=[\"text\"], num_proc = 1\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZ2SahY6QGuL"
   },
   "source": [
    "### üèóÔ∏è Build model (RoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1750163660990,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "GQSwO76hQHdF",
    "outputId": "f17df694-e58f-49db-daee-1878a0791c0b"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", num_labels=2,\n",
    "    hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYmTDUj5QIcq"
   },
   "source": [
    "### ‚öôÔ∏è TrainingArguments (ÌäúÎãùÎêú ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1750163664878,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "g5KQG-aVQJWg"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/roberta-output\",\n",
    "    per_device_train_batch_size=56,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=2,           # 3 -> 2\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    weight_decay=0.1,             # 0.01 -> 0.1\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    label_smoothing_factor=0.1,\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, metric_for_best_model=\"f1\",\n",
    "    logging_dir=\"./logs\", logging_steps=10, logging_first_step=True,\n",
    "    save_total_limit=1, run_name=\"roberta-ai-vs-human\", report_to=[\"tensorboard\"],\n",
    "    ddp_find_unused_parameters=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bgcyGIVQKqT"
   },
   "source": [
    "### üöÇ Trainer & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3003518,
     "status": "ok",
     "timestamp": 1750166670687,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "N5TuYER6QLeY",
    "outputId": "180ffd1f-6eb2-4001-d923-ad4d3b08a669"
   },
   "outputs": [],
   "source": [
    "# class LogCallback(TrainerCallback):\n",
    "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "#         if logs:\n",
    "#             now = dt.datetime.now().strftime(\"%H:%M:%S\")\n",
    "#             lr  = kwargs.get(\"optimizer\", {}).param_groups[0][\"lr\"] if \"optimizer\" in kwargs else logs.get(\"learning_rate\")\n",
    "#             watched = {**{k: logs.get(k) for k in [\"loss\",\"eval_loss\",\"eval_accuracy\",\"eval_f1\"]}, \"lr\": lr}\n",
    "#             msg = \" | \".join(f\"{k}: {v:.4f}\" for k,v in watched.items() if v is not None)\n",
    "#             print(f\"[{now}] step {state.global_step} | {msg}\")\n",
    "\n",
    "# Î°úÍ∑∏ ÏΩúÎ∞± ÏàòÏ†ï\n",
    "class LogCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            now = dt.datetime.now().strftime(\"%H:%M:%S\")\n",
    "            # ÏïàÏ†ïÏ†ÅÏúºÎ°ú logsÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "            lr = logs.get(\"learning_rate\", 0.0)\n",
    "            watched = {\n",
    "                \"loss\": logs.get(\"loss\"),\n",
    "                \"eval_loss\": logs.get(\"eval_loss\"),\n",
    "                \"eval_accuracy\": logs.get(\"eval_accuracy\"),\n",
    "                \"eval_f1\": logs.get(\"eval_f1\"),\n",
    "                \"lr\": lr,\n",
    "            }\n",
    "            msg = \" | \".join(f\"{k}: {v:.6f}\" if k == \"lr\" else f\"{k}: {v:.4f}\" for k,v in watched.items() if v is not None)\n",
    "            print(f\"[{now}] step {state.global_step} | {msg}\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return dict(\n",
    "        accuracy  = accuracy_score(labels, preds),\n",
    "        precision = precision_score(labels, preds),\n",
    "        recall    = recall_score(labels, preds),\n",
    "        f1        = f1_score(labels, preds),\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args,\n",
    "    train_dataset=train_ds, eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer, data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(2), LogCallback()],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJE5UpZsQNYD"
   },
   "source": [
    "### üß™ Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "executionInfo": {
     "elapsed": 78477,
     "status": "ok",
     "timestamp": 1750166810389,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "0uBDorFWQOFD",
    "outputId": "45e8dcb0-b621-43a5-add0-f27c626d7d13"
   },
   "outputs": [],
   "source": [
    "print(\"üìä Test metrics:\", trainer.evaluate(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8701f50f219f485b8d1be145fa4d5168",
      "1face25d8ff44e66bc72f42c2ef1b72a",
      "f33f816068fb41f1ab2fa1eb40f2d91b",
      "eb5434c6796d4f22b58ff90b421068b7",
      "ac87a5ea828e4f9f905072dfe4a91717",
      "05f65724415f449c81a93a265c341cfb",
      "693b72c3352640d993293f7726224e06",
      "e383f54f5e3e4edb84da1b4deb9014e9",
      "1ec56f871a0845baab88f48a800dd554",
      "ec2a66e4242f4f56abff55551841512f",
      "228a7ac42d0e4314a5e2a07446cdfa5e"
     ]
    },
    "executionInfo": {
     "elapsed": 45577,
     "status": "ok",
     "timestamp": 1750167524638,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "xdwGVtm-QPR_",
    "outputId": "a9384dc3-22dd-44b4-8106-51f04c219319"
   },
   "outputs": [],
   "source": [
    "# 1) Î™®Îç∏/ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∂àÎü¨Ïò§Í∏∞\n",
    "MODEL_DIR = \"/content/roberta-ai-vs-human\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_DIR)\n",
    "model     = RobertaForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# 2) DAIGT Îç∞Ïù¥ÌÑ∞ Î°úÎìú & Ï†ÑÏ≤òÎ¶¨\n",
    "DAIGT_PATH = \"/content/daigt.csv\"\n",
    "df = (pd.read_csv(DAIGT_PATH, usecols=[\"text\", \"generated\"])\n",
    "        .rename(columns={\"generated\":\"label\"})\n",
    "        .dropna(subset=[\"text\"]))\n",
    "df[\"text\"]  = df[\"text\"].astype(str).str.strip()\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "# 3) Head-Tail ÌÜ†ÌÅ¨ÎÇòÏù¥Ï¶à\n",
    "MAX_LEN, HEAD, TAIL = 512, 256, 254\n",
    "def ht_tokenize(batch):\n",
    "    ids_all, attn_all = [], []\n",
    "    for txt in batch[\"text\"]:\n",
    "        ids = tokenizer.encode(txt, add_special_tokens=True, truncation=False)\n",
    "        if len(ids) > MAX_LEN:\n",
    "            ids = ids[:HEAD+1] + ids[-TAIL:]\n",
    "        ids_all.append(ids)\n",
    "        attn_all.append([1]*len(ids))\n",
    "    return {\"input_ids\": ids_all, \"attention_mask\": attn_all}\n",
    "\n",
    "ds_test = Dataset.from_pandas(df[[\"text\",\"label\"]]).map(\n",
    "    ht_tokenize, batched=True, batch_size=1024,\n",
    "    num_proc=20, remove_columns=[\"text\"], desc=\"Tokenizing(DAIGT)\"\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 4) ÌÖåÏä§Ìä∏Ïö© Trainer\n",
    "def metrics(p):\n",
    "    y, pred = p.label_ids, p.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y, pred),\n",
    "        \"precision\": precision_score(y, pred),\n",
    "        \"recall\":    recall_score(y, pred),\n",
    "        \"f1\":        f1_score(y, pred),\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"tmp-eval\",\n",
    "        per_device_eval_batch_size=32,\n",
    "        dataloader_drop_last=False,\n",
    "        seed=42,\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=metrics,\n",
    ")\n",
    "\n",
    "# 5) ÌÖåÏä§Ìä∏ Ïã§Ìñâ\n",
    "results = trainer.evaluate(ds_test)\n",
    "print(\"\\nüìä DAIGT Test metrics\")\n",
    "for k,v in results.items():\n",
    "    if k.startswith(\"eval_\"):\n",
    "        print(f\"{k:12s}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5fneY1MQVI6"
   },
   "source": [
    "### üíæ Save model/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1477,
     "status": "ok",
     "timestamp": 1750167671578,
     "user": {
      "displayName": "ÏµúÎØºÏÑú",
      "userId": "17777814696807398999"
     },
     "user_tz": -540
    },
    "id": "k_R5jPPqQR-I",
    "outputId": "c63de7b1-9534-4a79-a920-66f1eba2a2a3"
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = \"/content/drive/MyDrive/final-tunned-roberta-ai-vs-human\"\n",
    "trainer.save_model(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "print(f\"Model & tokenizer saved to '{SAVE_PATH}'.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzCsH9ct+Dm3EjSJd/g9JN",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
